# Лабораторная работа №1. Настройка окружения и разведочный анализ данных

## Описание проекта
Данный проект создан в рамках выполнения лабораторной работы №1.  
Основная цель — подготовка структуры проекта, настройка рабочего окружения и проведение разведочного анализа данных (EDA).  
В дальнейшем этот проект будет развиваться при выполнении следующих лабораторных работ.

---

## Структура проекта
На текущем этапе структура проекта имеет вид:
```
lab_1iis
|_____ .venv_my_proj # виртуальное окружение
|_____ .git # локальный репозиторий
|_____ data # папка с исходными и промежуточными данными
| |___ dataset.csv # исходный датасет
| |___ clean_dataset.pkl # очищенный датасет
|
|_____ eda # папка с EDA
| |___ eda.ipynb # блокнот с разведочным анализом данных
|
|_____ graph # графики с EDA
|  |___ graph2.png
|  |___ ...
|
|_____ research # Ноутбук с графики исследований лучшей модели
|  |___ research.ipynb
|  |___ ...
|
|__ services                 # продакшн-часть: сервисы и мониторинг в Docker
|  |__ ml_service            # сервис для инференса обученной модели (FastAPI)
|  |  |__ main.py            # точка входа FastAPI-приложения, описание эндпоинтов
|  |  |__ api_handler.py     # обёртка для загрузки модели и выполнения predict
|  |  |__ requirements.txt   # зависимости, необходимые только для работы сервиса
|  |  |__ Dockerfile         # инструкция сборки Docker-образа ml_service
|  |
|  |__ requests              # сервис-генератор запросов к ml_service
|  |  |__ random_request.py  # скрипт отправки запросов к API
|  |  |__ requirements.txt   # зависимости генератора трафика
|  |  |__ Dockerfile         # сборка Docker-образа requests_service
|  |
|  |__ prometheus            # конфигурация Prometheus
|  |  |__ prometheus.yml     # описание jobs и targets (ml_service и др.)
|  |
|  |__ grafana               # файлы Grafana
|  |  |__ grafana.db         # база данных Grafana (дашборды, настройки)
|  |  |__ ml_dashboard.json  # экспортированный дашборд мониторинга
|  |  |__ ...                # служебные папки (csv, pdf, plugins, png)
|  |
|  |__ models                  # Артефакты обучения
|  |  |__ get_model.py         # Скрипт для получения модели из Mlflow
|  |  |__ model.pkl            # Обученная модель (RandomForest), используемая сервисом получить из скрипта
|
|_____ .gitignore
|_____ README.md
|_____ requirements.txt
```

## Запуск проекта
Чтобы развернуть проект на другой машине, выполните следующие шаги:

1. **Клонировать репозиторий:**
```textmate
git clone https://github.com/Halssara/lab1_iis.git
cd lab_1iis
```

2. **Создать и активировать виртуальное окружение:**
```textmate
python3 -m venv venv
source venv/bin/activate
```

3. **Установить зависимости:**
```textmate
pip install -r requirements.txt
```
4. **Загрузить датасет:**
https://www.kaggle.com/datasets/krishujeniya/heart-diseae
Скопируйте исходный `dataset.csv` в папку `data/`.

6. **Запустить EDA:**  
Открыть блокнот:
```textmate
jupyter notebook eda/eda.ipynb
```
## Результаты EDA

В ходе проведения разведочного анализа данных были выполнены следующие шаги:

1. **Загрузка и знакомство с данными**  
   - Определены числовые и категориальные признаки.  
   - Проверены типы данных 

2. **Очистка данных**  
   - Удалены дубликаты и невалидные значения.  
   - Обработаны пропущенные значения.

3. **Анализ признаков**  
   - Построены графики распределения фичей, матрица корреляции, распределение таргета относительно возраста, интерактивный график целевой переменной в осях холестерина и макимальной частоты биения сердца.  
   - Выявлены зависимости между признаками и целевой переменной.  
   - Определены признаки, которые могут сильно влиять на результат модели.  

4. **Создание новых признаков**  
   - Сформирован дополнительный признак из возраста  

5. **Сохранение данных**  
   - Финальный очищенный датасет сохранён в формате `.pkl` для корректного хранения типов данных.  



***
### Выводы которые были получены в ходе EDA

- Признак `oldpeak` — сильно смещён влево, большинство значений невысокие, есть длинный правый хвост. Значения выше 2 встречаются редко.
- Признак `thalach` (максимальная частота сердцебиения) имеет распределение, близкое к нормальному, большинство наблюдений в диапазоне 130–170.
- Признак `fbs` (повышенный сахар натощак) — почти у всех наблюдений значение 0, лишь небольшая часть имеет 1, признак дисбалансирован.
- Признак `restecg` — две «группы», почти равное разделение по двум значениям, что может указывать на диагностическую особенность.
- Признак `thal` — распределён по трем основным классам, выраженный дисбаланс.
- Признак `age` — нормальное распределение с пиком в районе 55–60 лет, малое число молодых и пожилых пациентов.
- Признак `slope` — две группы с разной популярностью, большая часть принимает значения 1 и 2.
- Признак `exang` (стенокардия при нагрузке) — основной класс 0, меньшинство с 1.
- Признак `chol` (уровень холестерина) имеет асимметричное распределение с выбросами вправо, большинство наблюдений в диапазоне 200–300.
- Признак `target` (наличие заболевания) — почти равномерно распределён по классам, что положительно для обучения модели.
- Признак `trestbps` (давление в покое) — распределение близко к нормальному, небольшой правый хвост.
- Признак `sex` — около двух третей мужчин, треть женщин.
- Признак `ca` (количество сосудов, окрашенных контрастом) — выраженный перекос в сторону нулевых значений.
- Признак `cp` (тип боли в груди) — наибольшая часть наблюдений приходится на класс 0, далее классы 2 и 1, а последний встречается редко.
- Корреляционная матрица показывает, что целевая переменная заметно зависит от признаков: `cp`, `thalach` (положительно), `oldpeak`, `exang`, `ca`, `slope` (отрицательно).
- Boxplot возраста по целевой переменной показывает: среди больных возрастное распределение смещено левее, чем у здоровых — то есть болезнь сердца встречается чаще среди относительно молодых пациентов данного исследования.
- По интерактивному графику "Холестерин видно, что пациенты с заболеванием сердца (target = 1, отмечены жёлтым цветом) имеют тенденцию к более высокой максимальной частоте сердцебиения (thalach), а распределение уровня холестерина (chol) в обеих группах перекрывается. Нет чёткой линейной зависимости между холестерином и сердечным заболеванием, однако большое число больных имеет thalach выше среднего. Также видно, что значения chol выше 400 встречаются только у больных, но выборка для таких случаев небольшая. В целом, максимальная частота сердцебиения потенциально является более информативным признаком для выделения целевой переменной, чем уровень холестерина.
***

### Основные выводы
- Данные успешно загружены и очищены.  
- Были выявлены статистические закономерности, которые помогут при построении модели.  
- Построены графики, подтверждающие зависимость целевой переменной от ключевых признаков.  
- Проект готов к дальнейшей разработке
- Возраст (`age`) имеет распределение с пиком около 55-60 лет, что важно учитывать при анализе риска.
- Признак максимальной частоты сердцебиения (`thalach`) ниже у пациентов с болезнью сердца, что может служить индикатором.
- Во многих категориальных признаках (например, `cp` — тип боли, `slope`) есть доминирующие значения, что поможет при создании категориальных признаков.
- Уровень холестерина (`chol`) в целом выше у больных, но есть значительное пересечение с группой здоровых, поэтому этот признак стоит использовать в сочетании с другими.
- Признаки, связанные с физическим состоянием сердца при нагрузке (`exang`, `oldpeak`), хорошо разделяют классы.
- Корреляционная матрица показывает, что признаки `cp`, `thalach`, `slope`, `oldpeak` и `exang` имеют заметные связи с целевой переменной.
- Признак `target` равномерно распределён, что положительно скажется на обучении модели без сильного перекоса классов.
- Пропущенные и аномальные значения были удалены, что улучшит качество модели.
---


# Лабораторная работа №2. Настройка и исследование моделей машинного обучения

## Цель работы
Основная цель лабораторной работы №2 — провести исследования по настройке и подбору параметров моделей машинного обучения для улучшения качества предсказаний на подготовленном датасете.

## Задачи работы
- Изучить методы предварительной настройки и отбора гиперпараметров моделей.
- Провести настройку различных моделей с использованием выбранных критериев.
- Произвести отбор признаков по важности.
- Провести оценку качества моделей по метрикам.
- Сравнить результаты различных настроек и подобрать лучшую конфигурацию.

## Описание процесса
- На основе подготовленного очищенного датасета построены модели машинного обучения, в том числе с использованием методов sklearn.
- Выполнено логирование модели и её параметров в MLflow.
- Изучены результаты работы модели, проведён отбор признаков с сохранением списка в отдельный JSON-файл.
- Зафиксированы зависимости качества моделей от используемых признаков.

## Результаты ЛР2
- Проведена настройка параметров моделей Random Forest, CatBoost.
- Настроена и зарегистрирована лучшая модель с её сигнатурой и логами.
- Выполнено логирование необходимых артефактов, в том числе файла `best_features.json` с набором выделенных признаков и `requirements.txt`.
- В интерфейсе MLflow отображаются результаты запусков, параметры, метрики и артефакты модели.

---

# Дополнительно

Для запуска mlflow выполнить

```ps1
mlflow server `
    --backend-store-uri sqlite:///mlruns.db `
    --default-artifact-root ./mlartifacts `
    --host localhost `
    --port 5000
```

После запуска откроыть в браузере http://localhost:5000 для просмотра результатов.

# ЛР 3 Создание сервиса предсказаний

## Описание сервиса

Папка `services/ml_service` содержит код REST‑сервиса для инференса модели:  
- `main.py` – FastAPI‑приложение с endpointом `/api/prediction/{item_id}`, описанием входных полей и формированием `pandas.DataFrame` для модели. 
- `api_handler.py` – обёртка над загруженной моделью (`joblib.load`), выполняющая предсказание по переданным признакам.
- `requirements.txt` – минимальные зависимости, необходимые только для работы сервиса (FastAPI, Uvicorn, pandas, numpy, scikit‑learn, joblib и др.).
- `Dockerfile` – рецепт сборки Docker‑образа на базе `python:3.11-slim` и команды для запуска Uvicorn внутри контейнера.

Папка `models` содержит файл обученной модели:  
- `model.pkl` – сериализованный RandomForest‑классификатор (или pipeline), который используется сервисом для предсказаний.

## Сборка Docker‑образа

Из директории `services/ml_service`:

```bash
docker build -t heart_ml_service:1 .
```

Здесь `heart_ml_service` – имя образа, `1` – первая версия образа согласно заданию.

## Запуск контейнера

Из той же директории:

```bash
docker run -p 8001:8000 -v "$(pwd)/../models:/models" --name heart_ml_service_container heart_ml_service:1
```

- `-p 8001:8000` – пробрасывает порт `8000` контейнера на порт `8001` хоста (доступ по `http://localhost:8001`).
- `-v "$(pwd)/../models:/models"` – монтирует локальную папку `../models` в `/models` внутри контейнера, откуда код загружает `model.pkl`.

## Проверка работоспособности

1. Открыть браузер и перейти по адресу:  
   `http://localhost:8001/docs` – автоматически сгенерированная Swagger‑документация FastAPI.
2. Найти метод `POST /api/prediction/{item_id}`, нажать **Try it out**, указать `item_id` (например, `"1"`).  
3. Вставить пример тела запроса:

```json
{
  "age": 67,
  "sex": 1,
  "cp": 0,
  "trestbps": 160,
  "chol": 286,
  "fbs": 0,
  "restecg": 0,
  "thalach": 108,
  "exang": 1,
  "oldpeak": 1.5,
  "slope": 1,
  "ca": 3,
  "thal": 2,
  "high_age": 1
}
```

4. Нажать **Execute** и убедиться, что сервис возвращает JSON с полями `item_id` и `predict` (классификация по обученной модели).

   Пример полученного ответа:
   ```json
   {
     "item_id": "1",
     "predict": 0
   }
   ```
   

# Лабораторная работа №4. Мониторинг сервиса с моделью

В рамках ЛР4 к ранее разработанному сервису машинного обучения добавлен стек мониторинга на базе Prometheus и Grafana.  
Цель работы — собирать метрики работы сервиса и модели, визуализировать их на дашборде и проанализировать поведение системы под нагрузкой.

***

## Используемые технологии

- Python, FastAPI — реализация REST‑сервиса с моделью.  
- scikit-learn / pickle — загрузка и применение обученной модели.  
- Prometheus + библиотека prometheus_client — сбор и экспозиция метрик сервиса.  
- Grafana — визуализация метрик и построение дашборда.  
- Docker, Docker Compose — упаковка сервисов и их совместный запуск.  

***

## Структура сервисов для мониторинга

Папка `services/`:

- `ml_service/`  
  - `main.py` — FastAPI‑приложение, эндпоинт для предсказаний, экспозиция метрик `/metrics`.  
  - `api_handler.py` (если есть) — вспомогательная логика обработки запросов.  
  - `models/` — сериализованная модель, используемая сервисом.  
  - `Dockerfile` — образ сервиса `ml_service`.  
  - Сервис поднимается на `http://ml_service:8000` (снаружи: `http://localhost:8001`), Swagger: `/docs`.

- `requests/`  
  - Скрипт(ы) генерации трафика к `ml_service` (периодические HTTP‑запросы для нагрузки и генерации метрик).  
  - `Dockerfile` — образ `requests_service`.  
  - Веб‑интерфейса нет, сервис работает в фоне.

- `prometheus/`  
  - `prometheus.yml` — конфигурация Prometheus: job для опроса `ml_service:8000/metrics` и других target‑ов при необходимости.  
  - Образ: `prom/prometheus:latest`.  
  - Веб‑интерфейс Prometheus: `http://localhost:9090`.

- `grafana/`  
  - `ml_dashboard.json` — экспортированный дашборд Grafana с панелями мониторинга.  
  - (При необходимости) папка данных Grafana, смонтированная в `/var/lib/grafana`.  
  - Образ: `grafana/grafana:latest`.  
  - Веб‑интерфейс Grafana: `http://localhost:3000`, логин/пароль: `admin/admin`.

Сервисы `database` и `pgadmin` в рамках данной лабораторной работы не поднимались, задания, связанные с БД, не выполнялись (по условию это допускается).

***

## Docker Compose и запуск проекта

Файл `services/compose.yml` описывает совместный запуск:

- `ml_service` — сервис с моделью.  
- `requests_service` — генератор запросов.  
- `prometheus` — сборщик метрик.  
- `grafana` — визуализация.

Запуск проекта:

```bash
cd services
docker compose -f compose.yml up --build
```

Остановка:

```bash
cd services
docker compose -f compose.yml down
```

После запуска сервисы доступны по адресам:

- ML‑сервис: `http://localhost:8001/docs` (Swagger)  
- Prometheus: `http://localhost:9090`  
- Grafana: `http://localhost:3000` (admin / admin)

***

## Метрики и мониторинг (Prometheus)

В `ml_service` реализованы пользовательские метрики, экспонируемые на `/metrics`, например:

- `ml_requests_total` — общее число запросов к API (counter).  
- `ml_requests_error_total{status="..."}` — количество ошибочных запросов по статус‑коду (4xx, 5xx).  
- `model_prediction_bucket` — гистограмма/бакеты распределения предсказаний модели.  
- `process_cpu_seconds_total`, `process_resident_memory_bytes` — инфраструктурные метрики процесса.

Примеры запросов в Prometheus:

- Частота запросов к сервису (RPS):

  ```promql
  avg(rate(ml_requests_total[1m]))
  avg(rate(ml_requests_total[1h]))
  ```

- Ошибки 4xx и 5xx (в минуту):

  ```promql
  sum(rate(ml_requests_error_total{status=~"4..|5.."}[1m]) * 60) by (status)
  ```

- Распределение предсказаний по классам через бакеты:

  ```promql
  rate(model_prediction_bucket{le="1.5"}[1m]) * 60
  rate(model_prediction_bucket{le="0.5"}[1m]) * 60
  (avg(rate(model_prediction_bucket{le="1.5"}[1m])) - avg(rate(model_prediction_bucket{le="0.5"}[1m]))) * 60
  ```

- Использование CPU:

  ```promql
  rate(process_cpu_seconds_total[1m])
  ```

- Использование памяти в МБ:

  ```promql
  process_resident_memory_bytes / 1048576
  ```

Скриншоты с графиками Prometheus прикладываются в репозиторий и демонстрируют поведение этих метрик под нагрузкой.

### Гистограма предсказаний модели
![ml_predicts_lr4.png](images%2Fml_predicts_lr4.png)

### Частота (rate) запросов к основному сервису в минуту
![req_rate_prometheus_lr4.png](images%2Freq_rate_prometheus_lr4.png)

### Количество запросов к сервису с кодами ошибок 4** и 5** (две линии на одном графике).
![req_errors_lr4.png](images%2Freq_errors_lr4.png)


***

## Дашборд Grafana

В Grafana создан отдельный дашборд (экспортирован в `services/grafana/ml_dashboard.json`), который использует источник данных Prometheus (`http://prometheus:9090`).  
Дашборд содержит минимум 5 графиков разных уровней мониторинга.

Основные панели:

1. «Requests rate (RPS)» — прикладной уровень  
   - Запросы:

        `avg(rate(ml_requests_total[1m]))`

        `avg(rate(ml_requests_total[1h]))`  

   - Показывает частоту запросов к API, сглаженную по окну 1 минута и 1 час.

2. «4xx and 5xx errors» — прикладной уровень  
   - Запрос: `sum(rate(ml_requests_error_total{status=~"4..|5.."}[1m]) * 60) by (status)`  
   - Две линии: частота ошибок с кодами 4xx и 5xx, в ошибках в минуту.

3. «Predictions rate by class» — уровень качества модели / data shift  
   - Запросы на основе `model_prediction_bucket`, например:  
     - класс 0: `rate(model_prediction_bucket{le="0.5"}[1m]) * 60`  
     - класс 1: разность бакетов `(avg(rate(model_prediction_bucket{le="1.5"}[1m])) - avg(rate(model_prediction_bucket{le="0.5"}[1m]))) * 60`  
   - По изменению соотношения классов во времени можно судить о возможном data shift.

4. «ML service CPU usage (seconds/s)» — инфраструктурный уровень  
   - Запрос: `rate(process_cpu_seconds_total[1m])`  
   - Отражает загрузку CPU процессом сервиса.

5. «ML service memory usage (MiB)» — инфраструктурный уровень  
   - Запрос: `process_resident_memory_bytes / 1048576` с единицами оси в MiB.  
   - Показывает потребление оперативной памяти сервисом.

Скриншот итогового дашборда (`images/grafana_dashboard.png`) добавлен в репозиторий и демонстрирует работу всех панелей одновременно.
![dashboard.png](images%2Fdashboard.png)
***

## Импорт/экспорт дашборда

- Для экспорта дашборда из Grafana используется меню Dashboard settings → JSON model → Download JSON, файл сохранён как `grafana/ml_dashboard.json`.  
- Для повторного использования дашборда его можно импортировать через Grafana: Dashboards → Import → Upload JSON file → выбрать `ml_dashboard.json`.